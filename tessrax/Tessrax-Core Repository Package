# Tessrax-Core Repository Package

Complete file structure for public release of contradiction-driven governance system.

-----

## File: `README.md`

```markdown
# Tessrax-Core

**A contradiction-driven governance prototype. Where disagreement becomes data.**

Tessrax-Core is a minimal open prototype of a **contradiction-driven governance system** for multi-agent AI coordination.

## What It Does

It demonstrates:
- **Multi-agent contradiction detection** (CE-MOD-66)
- **Governance routing** (autonomic / deliberative / constitutional / audit)
- **Stability scoring and visualization**

The goal: show how disagreement between AIs can be used to **measure epistemic stability** and guide rule formation.

## Quick Start

```bash
# Setup
chmod +x setup.sh
./setup.sh
source .venv/bin/activate

# Run demo
python governance_kernel.py

# Visualize
python visualize_scaffolding.py
```

## Architecture

```
Agent Claims â†’ CE-MOD-66 â†’ Contradiction Graph â†’ Governance Kernel â†’ Ledger
```

See `docs/architecture_overview.md` for technical details.

## Philosophy

Traditional AI systems try to eliminate disagreement. Tessrax treats contradiction as **signal**â€”a measurement of where knowledge, values, or definitions are unstable.

When multiple AIs disagree:

- **Low contradiction** (S > 0.9) â†’ Safe to auto-adopt
- **Medium contradiction** (0.7-0.9) â†’ Needs human deliberation
- **High contradiction** (0.5-0.7) â†’ Constitutional drift; amend rules
- **Extreme contradiction** (< 0.5) â†’ Behavioral audit; check for manipulation

## Repository Structure

```
Tessrax-Core/
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ setup.sh
â”œâ”€â”€ ce_mod_66.py                 # Contradiction Graph Engine
â”œâ”€â”€ governance_kernel.py         # Routing + governance lanes
â”œâ”€â”€ visualize_scaffolding.py     # Basic visualization script
â”œâ”€â”€ data/
â”‚   â””â”€â”€ sample_agent_runs.json   # mock multi-agent answers
â”œâ”€â”€ ledger/
â”‚   â””â”€â”€ example_ledger.jsonl     # synthetic receipts
â”œâ”€â”€ policies/
â”‚   â””â”€â”€ example_policy.md        # sample governance document
â””â”€â”€ docs/
    â””â”€â”€ architecture_overview.md
```

## Contributing

This is a research prototype. Contributions welcome:

- New contradiction detection methods
- Alternative routing algorithms
- Visualization improvements
- Real-world use case implementations

## License

MIT

## Citation

```
Tessrax-Core: A Contradiction-Driven Governance Framework
Josh Vetos, 2025
https://github.com/joshuavetos/Tessrax-Core
```

-----

*Built for transparency. Designed for truth maintenance.*

```
---

## File: `requirements.txt`
```

networkx>=3.3
matplotlib>=3.8

```
---

## File: `setup.sh`

```bash
#!/usr/bin/env bash
# Tessrax-Core setup script

echo "ðŸ§± Setting up Tessrax-Core environment..."
python3 -m venv .venv
source .venv/bin/activate
pip install --upgrade pip
pip install -r requirements.txt

echo "âœ… Environment ready."
echo ""
echo "Run the sample demo:"
echo "  python governance_kernel.py"
echo ""
echo "Visualize contradictions:"
echo "  python visualize_scaffolding.py"
```

-----

## File: `ce_mod_66.py`

```python
"""
CE-MOD-66 â€” Contradiction Graph Engine (public build)

Builds a graph of agent claims and detects contradictions.
Computes stability index: S = 1 - (contradictions / total_edges)
"""
import json
import itertools
import networkx as nx


def detect_contradictions(agent_claims):
    """
    Build contradiction graph from a list of {agent, claim, type}.
    
    Args:
        agent_claims: List of dicts with keys 'agent', 'claim', 'type'
    
    Returns:
        NetworkX Graph with contradiction edges
    """
    G = nx.Graph()
    
    for a in agent_claims:
        G.add_node(a["agent"], claim=a["claim"], ctype=a["type"])
    
    for a, b in itertools.combinations(agent_claims, 2):
        if a["claim"] != b["claim"]:
            G.add_edge(a["agent"], b["agent"], contradiction=True)
        else:
            G.add_edge(a["agent"], b["agent"], contradiction=False)
    
    return G


def score_stability(G):
    """
    Calculate stability index for a contradiction graph.
    
    S = 1 - (contradictory_edges / total_edges)
    
    Returns:
        Float between 0 (total disagreement) and 1 (total consensus)
    """
    total_edges = len(G.edges)
    if total_edges == 0:
        return 1.0
    
    contradictions = sum(1 for _, _, d in G.edges(data=True) if d.get("contradiction"))
    return 1 - (contradictions / total_edges)


if __name__ == "__main__":
    # Demo run
    with open("data/sample_agent_runs.json") as f:
        runs = json.load(f)
    
    G = detect_contradictions(runs)
    stability = score_stability(G)
    
    print(f"ðŸ“Š Contradiction Analysis:")
    print(f"   Agents: {len(G.nodes)}")
    print(f"   Edges: {len(G.edges)}")
    print(f"   Stability Index: {stability:.2f}")
```

-----

## File: `governance_kernel.py`

```python
"""
Governance Kernel â€” routes contradictions into lanes

Lanes:
  - Autonomic: S > 0.9 (safe to auto-adopt)
  - Deliberative: 0.7 < S â‰¤ 0.9 (needs human review)
  - Constitutional: 0.5 < S â‰¤ 0.7 (rules drifting)
  - Behavioral Audit: S â‰¤ 0.5 (possible manipulation)
"""
import json
from ce_mod_66 import detect_contradictions, score_stability


def route(G):
    """
    Route a contradiction graph into governance lane.
    
    Returns:
        Dict with stability score and assigned lane
    """
    stability = score_stability(G)
    
    if stability > 0.9:
        lane = "autonomic"
    elif stability > 0.7:
        lane = "deliberative"
    elif stability > 0.5:
        lane = "constitutional"
    else:
        lane = "behavioral_audit"
    
    return {
        "stability": round(stability, 3),
        "lane": lane
    }


if __name__ == "__main__":
    # Demo run
    with open("data/sample_agent_runs.json") as f:
        runs = json.load(f)
    
    G = detect_contradictions(runs)
    result = route(G)
    
    print(f"ðŸŽ¯ Governance Routing:")
    print(f"   Stability: {result['stability']}")
    print(f"   Lane: {result['lane'].upper()}")
    print()
    
    # Explain the routing
    lane_descriptions = {
        "autonomic": "High consensusâ€”safe to auto-adopt",
        "deliberative": "Moderate conflictâ€”needs human quorum",
        "constitutional": "High conflictâ€”rule drift detected",
        "behavioral_audit": "Extreme conflictâ€”check for manipulation"
    }
    
    print(f"   Interpretation: {lane_descriptions[result['lane']]}")
```

-----

## File: `visualize_scaffolding.py`

```python
"""
Quick visualizer for contradiction graphs.

Renders nodes (agents) and edges (contradictions) using NetworkX.
Red edges = contradiction, gray edges = agreement.
"""
import json
import matplotlib.pyplot as plt
import networkx as nx
from ce_mod_66 import detect_contradictions


def visualize(agent_claims, title="Contradiction Graph"):
    """
    Visualize agent contradiction graph.
    
    Args:
        agent_claims: List of agent claim dicts
        title: Graph title
    """
    G = detect_contradictions(agent_claims)
    
    # Layout
    pos = nx.spring_layout(G, seed=42)
    
    # Color edges by contradiction
    edge_colors = ["red" if d.get("contradiction") else "gray" 
                   for _, _, d in G.edges(data=True)]
    
    # Draw
    plt.figure(figsize=(10, 8))
    nx.draw(
        G, pos,
        with_labels=True,
        edge_color=edge_colors,
        node_color="#B0E0E6",
        node_size=1500,
        font_size=10,
        font_weight="bold",
        width=2
    )
    
    plt.title(title, fontsize=16, fontweight="bold")
    plt.tight_layout()
    plt.show()


if __name__ == "__main__":
    with open("data/sample_agent_runs.json") as f:
        runs = json.load(f)
    
    print("ðŸ” Visualizing contradiction graph...")
    visualize(runs, title="Sample Agent Claims: Contradiction Analysis")
```

-----

## File: `data/sample_agent_runs.json`

```json
[
  {"agent": "GPT", "claim": "Option A", "type": "normative"},
  {"agent": "Gemini", "claim": "Option A", "type": "normative"},
  {"agent": "Grok", "claim": "Option B", "type": "normative"},
  {"agent": "Copilot", "claim": "Option A", "type": "normative"},
  {"agent": "Perplexity", "claim": "Option B", "type": "normative"},
  {"agent": "Meta", "claim": "Option A", "type": "normative"}
]
```

-----

## File: `ledger/example_ledger.jsonl`

```jsonl
{"timestamp":"2025-10-10T23:59Z","stability_index":0.83,"governance_lane":"deliberative","note":"Demo run on sample_agent_runs.json"}
```

-----

## File: `policies/example_policy.md`

```markdown
# Example Policy: AI Personhood Consideration

## Question
Should an AI system demonstrating consistent self-reflection be granted limited legal personhood?

## Context
This is a sample policy question used to test governance routing in Tessrax-Core.

## Agent Claims (Sample)

- **GPT**: "Noâ€”legal personhood requires biological substrate"
- **Claude**: "Conditional yesâ€”if self-reflection is verifiable and consistent"
- **Gemini**: "Noâ€”self-reflection can be simulated without consciousness"
- **Grok**: "Yesâ€”functional equivalence should determine status"
- **Perplexity**: "Inconclusiveâ€”need clearer definition of 'self-reflection'"

## Expected Routing
High normative contradiction â†’ **Constitutional Lane**

Suggests need for clearer definitions of:
- "Self-reflection"
- "Legal personhood"
- Verification criteria

## Next Steps
1. Route to deliberative quorum
2. Clarify constitutional definitions
3. Re-run with refined policy language
4. Log amendments to ledger
```

-----

## File: `docs/architecture_overview.md`

```markdown
# Tessrax-Core Architecture Overview

Tessrax-Core demonstrates how multi-agent contradiction analysis can become a
governance mechanism. It's a lightweight version of the full Tessrax stack.

---

## Core Modules

### CE-MOD-66 (`ce_mod_66.py`)
Builds the contradiction graph and computes a **stability index (S)**.

- **Nodes:** agent identities
- **Edges:** contradictions between claims
- **Edge attribute:** `contradiction=True/False`

The stability index is defined as:
```

S = 1 - (contradictory_edges / total_edges)

```
Where:
- S = 1.0 â†’ Perfect consensus
- S = 0.5 â†’ Half the agents disagree
- S = 0.0 â†’ Total disagreement

### Governance Kernel (`governance_kernel.py`)
Routes the current contradiction graph into one of four governance lanes:

| Lane | Stability Range | Description |
|------|-----------------|-------------|
| Autonomic | S > 0.9 | High consensus; safe to auto-adopt |
| Deliberative | 0.7 < S â‰¤ 0.9 | Needs structured human review |
| Constitutional | 0.5 < S â‰¤ 0.7 | Rules drifting; amend definitions |
| Behavioral Audit | S â‰¤ 0.5 | Possible bias or manipulation |

Each evaluation produces a JSON receipt for the ledger.

### Visualize Scaffolding (`visualize_scaffolding.py`)
Renders the contradiction graph using **NetworkX** and **Matplotlib**.

- Red edges indicate contradiction
- Gray edges indicate agreement
- Node layout shows consensus clusters

---

## Data Flow
```

agent_runs.json â†’ CE-MOD-66 â†’ Governance Kernel â†’ Ledger
â†“
Contradiction Graph
â†“
Visualization

```
Each step is auditable; the outputs can be version-controlled as research data.

---

## Extending Tessrax-Core

### Add New Agent Claims
Replace `data/sample_agent_runs.json` with new claim sets:

```json
[
  {"agent": "NewModel", "claim": "Your claim here", "type": "epistemic"}
]
```

### Add Contradiction Types

Extend `ce_mod_66.py` to detect:

- Temporal contradictions (ordering conflicts)
- Semantic contradictions (same word, different meaning)
- Normative contradictions (value conflicts)

### Log to Ledger

Append results to `ledger/example_ledger.jsonl`:

```python
import json
from datetime import datetime

result = route(G)
log_entry = {
    "timestamp": datetime.utcnow().isoformat() + "Z",
    "stability_index": result["stability"],
    "governance_lane": result["lane"],
    "note": "Your description here"
}

with open("ledger/example_ledger.jsonl", "a") as f:
    f.write(json.dumps(log_entry) + "\n")
```

### Visualize History

Plot stability over time:

```python
import json
import matplotlib.pyplot as plt

with open("ledger/example_ledger.jsonl") as f:
    logs = [json.loads(line) for line in f]

timestamps = [log["timestamp"] for log in logs]
stability = [log["stability_index"] for log in logs]

plt.plot(timestamps, stability)
plt.ylabel("Stability Index")
plt.xlabel("Time")
plt.title("Stability Drift Over Time")
plt.show()
```

-----

## Theoretical Foundation

Tessrax-Core operationalizes several key concepts:

### 1. Contradiction as Measurement

Instead of treating disagreement as error, we treat it as **data about epistemic state**.

### 2. Governance Without Adjudication

The system doesnâ€™t pick winnersâ€”it routes conflicts to appropriate resolution mechanisms.

### 3. Metabolic Learning

Amendments are tested for their effect on system stability. Good rules increase coherence; bad rules are reverted.

### 4. Institutional Memory

The ledger creates a case law of contradictionsâ€”showing which conflicts were resolved and how.

-----

## Research Applications

- **AI Safety**: Detect value drift in deployed systems
- **Policy Testing**: Stress-test governance documents against multi-agent interpretation
- **Truth Maintenance**: Track factual drift across model versions
- **Coordination**: Enable multi-agent systems to self-regulate

-----

## Limitations

This is a **minimal prototype**. The full Tessrax system includes:

- Semantic conflict detection (not just exact string matching)
- Weighted agent reliability scores
- Human deliberation protocols
- Constitutional amendment mechanisms
- Adversarial resistance testing

-----

## License

MIT

## Contact

For questions or collaboration: [Your contact info]

-----

*â€œWhere disagreement becomes data.â€*

```
---

## Deployment Commands

```bash
# Create repository
mkdir Tessrax-Core
cd Tessrax-Core

# Copy all files above into appropriate locations

# Initialize Git
git init
git add .
git commit -m "Initial public release: Tessrax-Core v0.1"
git branch -M main

# Add remote and push
git remote add origin https://github.com/joshuavetos/Tessrax-Core.git
git push -u origin main

# Create release tag
git tag -a v0.1 -m "Tessrax-Core v0.1 - Public prototype release"
git push origin v0.1
```

-----

## Repository Description (for GitHub)

**Short description:**

```
A contradiction-driven governance prototype. Where disagreement becomes data.
```

**Topics/Tags:**

```
ai-governance
multi-agent-systems
contradiction-detection
epistemic-stability
ai-safety
constitutional-ai
research-prototype
```

**About section:**

```
Tessrax-Core demonstrates how AI disagreement can be used as a governance signal. 
It detects contradictions between multiple AI agents and routes them into 
appropriate resolution mechanismsâ€”turning conflict into institutional memory.
```