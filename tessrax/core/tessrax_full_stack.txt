=== FILE: semantic_analyzer.py ===
"""
Tessrax Semantic Analyzer  —  v12.0
------------------------------------
Performs semantic and linguistic contradiction analysis using embeddings
and negation/antonym heuristics.  Falls back gracefully if ML packages
are missing.

Dependencies (auto-installed if absent):
    sentence-transformers
    nltk
"""

import importlib, subprocess, sys, re, math, json

# --- Auto-install helper -------------------------------------------------------
def ensure(pkg):
    if importlib.util.find_spec(pkg) is None:
        print(f"[setup] installing {pkg} …")
        subprocess.check_call([sys.executable, "-m", "pip", "install", pkg, "--quiet"])

for _pkg in ("sentence_transformers", "nltk"):
    try:
        ensure(_pkg)
    except Exception as e:
        print(f"[warn] could not auto-install {_pkg}: {e}")

# --- Conditional imports -------------------------------------------------------
try:
    from sentence_transformers import SentenceTransformer, util
    _HAS_ST = True
    _model = SentenceTransformer("all-MiniLM-L6-v2")
except Exception:
    _HAS_ST = False
    _model = None

try:
    import nltk
    from nltk.corpus import wordnet as wn
    nltk.download("wordnet", quiet=True)
except Exception:
    wn = None

# ------------------------------------------------------------------------------
class SemanticAnalyzer:
    """Hybrid semantic contradiction scorer."""

    def __init__(self):
        self.model = _model
        self.has_embeddings = _HAS_ST
        self.use_wordnet = wn is not None

    # ------------------------------------------------------------------
    def _embedding_similarity(self, a: str, b: str) -> float:
        if not self.has_embeddings:
            return 0.0
        ea, eb = self.model.encode([a, b], convert_to_tensor=True)
        sim = float(util.cos_sim(ea, eb))
        return sim

    # ------------------------------------------------------------------
    def _negation_conflict(self, a: str, b: str) -> bool:
        neg_words = {"not","never","no","none","neither","cannot","can't"}
        a_has = any(w in a.lower().split() for w in neg_words)
        b_has = any(w in b.lower().split() for w in neg_words)
        return a_has != b_has

    # ------------------------------------------------------------------
    def _antonym_conflict(self, a: str, b: str) -> bool:
        if not self.use_wordnet:
            return False
        tokens_a = re.findall(r"\b\w+\b", a.lower())
        tokens_b = re.findall(r"\b\w+\b", b.lower())
        for t1 in tokens_a:
            for syn in wn.synsets(t1):
                for lemma in syn.lemmas():
                    for ant in lemma.antonyms():
                        if ant.name() in tokens_b:
                            return True
        return False

    # ------------------------------------------------------------------
    def analyze(self, a: str, b: str) -> dict:
        """Return contradiction analysis dict."""
        result = {
            "pair": [a, b],
            "contradiction_type": None,
            "severity": 0.0,
            "confidence": 0.0,
            "reason": ""
        }

        # Semantic distance
        sim = self._embedding_similarity(a, b)
        result["semantic_similarity"] = round(sim, 3)

        neg_conf = self._negation_conflict(a, b)
        ant_conf = self._antonym_conflict(a, b)

        if neg_conf or ant_conf or sim < 0.2:
            result["contradiction_type"] = (
                "Negation" if neg_conf else "Antonym" if ant_conf else "Semantic"
            )
            # Heuristic severity and confidence
            result["severity"] = round(1 - sim, 3)
            conf = 0.7 + (0.1 if neg_conf or ant_conf else 0)
            result["confidence"] = min(conf, 1.0)
            reason_bits = []
            if neg_conf: reason_bits.append("negation mismatch")
            if ant_conf: reason_bits.append("antonym relation")
            if sim < 0.2: reason_bits.append("low semantic similarity")
            result["reason"] = ", ".join(reason_bits)
        else:
            result["contradiction_type"] = "None"
            result["severity"] = round(1 - sim, 3)
            result["confidence"] = 1 - result["severity"]
            result["reason"] = "High semantic similarity; no contradiction detected."

        return result


if __name__ == "__main__":
    sa = SemanticAnalyzer()
    tests = [
        ("AI is safe", "AI is dangerous"),
        ("The sky is blue", "The sky is not blue"),
        ("Cats are animals", "Dogs are animals"),
    ]
    for a,b in tests:
        print(json.dumps(sa.analyze(a,b), indent=2))
        print("-"*40)

=== FILE: semantic_analyzer.py (END) ===


=== FILE: contradiction_engine.py ===
"""
Tessrax Contradiction Engine — v12.0
------------------------------------
Coordinates semantic analyzer, assigns contradiction IDs,
and exports JSON summaries.
"""

import json, uuid, datetime
from semantic_analyzer import SemanticAnalyzer


class ContradictionRecord:
    def __init__(self, a:str, b:str, analysis:dict):
        self.id = f"C-{uuid.uuid4().hex[:8]}"
        self.timestamp = datetime.datetime.utcnow().isoformat()+"Z"
        self.statement_a = a
        self.statement_b = b
        self.analysis = analysis

    def to_dict(self):
        return {
            "id": self.id,
            "timestamp": self.timestamp,
            "a": self.statement_a,
            "b": self.statement_b,
            **self.analysis
        }


class ContradictionEngine:
    """Collects, analyzes, and summarizes contradictions."""

    def __init__(self):
        self.analyzer = SemanticAnalyzer()
        self.records = []

    def analyze_pair(self, a:str, b:str):
        analysis = self.analyzer.analyze(a,b)
        rec = ContradictionRecord(a,b,analysis)
        self.records.append(rec)
        return rec.to_dict()

    def summary(self):
        if not self.records:
            return {"count":0,"avg_severity":0.0,"avg_confidence":0.0}
        n = len(self.records)
        avg_sev = sum(r.analysis["severity"] for r in self.records)/n
        avg_conf = sum(r.analysis["confidence"] for r in self.records)/n
        return {
            "count": n,
            "avg_severity": round(avg_sev,3),
            "avg_confidence": round(avg_conf,3),
            "records":[r.to_dict() for r in self.records]
        }

    def export_json(self, path:str="contradictions.json"):
        with open(path,"w",encoding="utf-8") as f:
            json.dump(self.summary(),f,indent=2)
        return path


if __name__=="__main__":
    ce = ContradictionEngine()
    pairs = [
        ("AI is safe","AI is dangerous"),
        ("Water freezes at 0C","Water does not freeze at 0C"),
        ("The cat is black","The cat is white"),
    ]
    for a,b in pairs:
        res = ce.analyze_pair(a,b)
        print(json.dumps(res,indent=2))
    print("\nSummary:\n",json.dumps(ce.summary(),indent=2))

=== FILE: contradiction_engine.py (END) ===

=== FILE: governance_kernel.py ===
"""
Tessrax Governance Kernel — v12.0
----------------------------------
Evaluates contradiction events, simulates weighted quorum voting,
and maintains a Merkle-linked ledger.
"""

import json, hashlib, datetime, random
from pathlib import Path


class GovernanceKernel:
    def __init__(self, policy_path: str | None = None):
        self.ledger: list[dict] = []
        self.rules = self._load_rules(policy_path)

    # --------------------------------------------------------------
    def _load_rules(self, path: str | None) -> dict:
        default = {
            "audit": 0.9,
            "synthesis": 0.85,
            "implementer": 0.7,
            "research": 0.8
        }
        if not path:
            return default
        try:
            with open(path, "r", encoding="utf-8") as f:
                return json.load(f)
        except Exception:
            return default

    # --------------------------------------------------------------
    def _hash(self, text: str) -> str:
        return hashlib.sha256(text.encode()).hexdigest()

    def _previous_hash(self) -> str:
        return self.ledger[-1]["hash"] if self.ledger else "0" * 64

    # --------------------------------------------------------------
    def evaluate_policy(self, event: dict) -> dict:
        """Simulate a weighted quorum decision."""
        votes = {}
        for role, prob in self.rules.items():
            votes[role] = random.random() < prob
        approval_ratio = sum(votes.values()) / len(votes)
        approved = approval_ratio >= 0.75

        payload_str = json.dumps(event, sort_keys=True)
        h = self._hash(self._previous_hash() + payload_str)
        rec = {
            "id": f"L-{len(self.ledger)+1:04d}",
            "timestamp": datetime.datetime.utcnow().isoformat()+"Z",
            "event": event,
            "votes": votes,
            "approved": approved,
            "hash": h
        }
        self.ledger.append(rec)
        return rec

    # --------------------------------------------------------------
    def verify_chain(self) -> bool:
        """Recompute all hashes to confirm integrity."""
        prev = "0" * 64
        for rec in self.ledger:
            exp = self._hash(prev + json.dumps(rec["event"], sort_keys=True))
            if exp != rec["hash"]:
                return False
            prev = rec["hash"]
        return True

    # --------------------------------------------------------------
    def export_ledger(self, path: str = "ledger.json") -> Path:
        with open(path, "w", encoding="utf-8") as f:
            json.dump(self.ledger, f, indent=2)
        return Path(path)


if __name__ == "__main__":
    gk = GovernanceKernel()
    ev = {"type": "Normative", "payload": {"severity": 0.8}}
    for _ in range(3):
        gk.evaluate_policy(ev)
    print(json.dumps(gk.ledger, indent=2))
    print("Chain OK?", gk.verify_chain())

=== FILE: governance_kernel.py (END) ===


=== FILE: metabolism_adapter.py ===
"""
Tessrax Metabolism Adapter — v12.0
-----------------------------------
Normalizes contradiction events into entropy-weighted metabolic entries.
"""

import hashlib, json, math, time


class MetabolismAdapter:
    def __init__(self):
        self.events: list[dict] = []

    def _entropy(self, payload: dict) -> float:
        """Entropy proxy = normalized hash variance."""
        h = hashlib.sha1(json.dumps(payload, sort_keys=True).encode()).hexdigest()
        val = int(h[:8], 16) / 0xFFFFFFFF
        return round(val, 4)

    def ingest(self, contradiction: dict) -> dict:
        ent = self._entropy(contradiction)
        rec = {
            "id": f"ENT-{len(self.events)+1:04d}",
            "timestamp": time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime()),
            "payload": contradiction,
            "entropy": ent,
            "stability": round(1.0 - ent, 4)
        }
        self.events.append(rec)
        return rec

    def summary(self) -> dict:
        if not self.events:
            return {"count": 0, "avg_entropy": 0.0}
        avg = sum(e["entropy"] for e in self.events) / len(self.events)
        return {"count": len(self.events), "avg_entropy": round(avg, 4)}

    def export(self, path: str = "metabolism.json") -> str:
        with open(path, "w", encoding="utf-8") as f:
            json.dump(self.events, f, indent=2)
        return path


if __name__ == "__main__":
    from contradiction_engine import ContradictionEngine
    ce = ContradictionEngine()
    c = ce.analyze_pair("Policy open", "Policy closed")
    ma = MetabolismAdapter()
    e = ma.ingest(c)
    print(json.dumps(e, indent=2))
    print(ma.summary())

=== FILE: metabolism_adapter.py (END) ===


=== FILE: world_receipt_protocol.py ===
"""
World Receipt Protocol — v12.0
-------------------------------
Public FastAPI service for submitting signed contradiction receipts
and verifying the Merkle chain.
"""

import json, datetime, hashlib
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from governance_kernel import GovernanceKernel

app = FastAPI(title="World Receipt Protocol", version="2.0")
kernel = GovernanceKernel()


class Receipt(BaseModel):
    sender: str
    payload: dict
    signature: str


def verify_signature(sender: str, payload: dict, signature: str) -> bool:
    """Simple SHA-256 signature check demo."""
    check = hashlib.sha256(json.dumps(payload, sort_keys=True).encode()).hexdigest()
    return check[:10] == signature[:10]


@app.post("/submit")
def submit_receipt(receipt: Receipt):
    if not verify_signature(receipt.sender, receipt.payload, receipt.signature):
        raise HTTPException(status_code=403, detail="Invalid signature")
    record = kernel.evaluate_policy({
        "sender": receipt.sender,
        "payload": receipt.payload,
        "signature": receipt.signature
    })
    return {"status": "accepted", "ledger_id": record["id"], "hash": record["hash"]}


@app.get("/ledger")
def get_ledger():
    return {"count": len(kernel.ledger), "ledger": kernel.ledger}


@app.get("/verify_chain")
def verify_chain():
    ok = kernel.verify_chain()
    return {"chain_valid": ok, "entries": len(kernel.ledger)}


if __name__ == "__main__":
    import uvicorn
    print("🌐 World Receipt Protocol running on http://localhost:8080")
    uvicorn.run(app, host="0.0.0.0", port=8080)

=== FILE: world_receipt_protocol.py (END) ===

=== FILE: dashboard/app.py ===
"""
Tessrax Dashboard — v12.0
--------------------------
Flask + D3.js dashboard for live visualization of contradictions.
Auto-launches on port 8090 when invoked from current.py.
"""

from flask import Flask, render_template_string, jsonify
import threading, time, json, os
from pathlib import Path

# Minimal HTML + D3 page
_TEMPLATE = """
<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8" />
<title>Tessrax Dashboard</title>
<script src="https://d3js.org/d3.v7.min.js"></script>
<style>
  body{background:#0A0A23;color:#F7F7F7;font-family:Arial;margin:0;padding:0;}
  h1{background:#00BFFF;color:#0A0A23;padding:1rem;}
  svg{width:100%;height:80vh;}
  circle{stroke:#F7F7F7;stroke-width:1px;}
  line{stroke:#999;}
</style>
</head>
<body>
<h1>Tessrax Contradiction Graph</h1>
<svg id="graph"></svg>
<script>
async function loadData(){
  const res = await fetch("/data");
  return res.json();
}
function render(data){
  const svg=d3.select("#graph");
  svg.selectAll("*").remove();
  const width=window.innerWidth, height=window.innerHeight*0.8;
  const nodes=data.nodes, links=data.links;
  const sim=d3.forceSimulation(nodes)
    .force("link", d3.forceLink(links).id(d=>d.id).distance(120))
    .force("charge", d3.forceManyBody().strength(-250))
    .force("center", d3.forceCenter(width/2,height/2));
  const link=svg.append("g").selectAll("line").data(links).enter().append("line");
  const node=svg.append("g").selectAll("circle").data(nodes).enter()
    .append("circle")
    .attr("r",d=>8+8*d.severity)
    .attr("fill",d=>d3.interpolateTurbo(d.severity))
    .call(drag(sim));
  node.append("title").text(d=>d.label);
  sim.on("tick",()=>{
    link.attr("x1",d=>d.source.x).attr("y1",d=>d.source.y)
        .attr("x2",d=>d.target.x).attr("y2",d=>d.target.y);
    node.attr("cx",d=>d.x).attr("cy",d=>d.y);
  });
}
function drag(sim){
  function start(event,d){if(!event.active)sim.alphaTarget(0.3).restart();d.fx=d.x;d.fy=d.y;}
  function drag(event,d){d.fx=event.x;d.fy=event.y;}
  function end(event,d){if(!event.active)sim.alphaTarget(0);d.fx=d.fy=null;}
  return d3.drag().on("start",start).on("drag",drag).on("end",end);
}
async function main(){
  const data=await loadData();
  render(data);
}
main();
setInterval(main,5000);
</script>
</body>
</html>
"""

app = Flask(__name__)

DATA_PATH = Path("contradictions.json")

@app.route("/")
def index():
    return render_template_string(_TEMPlATE if False else _TEMPLATE)

@app.route("/data")
def data():
    if DATA_PATH.exists():
        with open(DATA_PATH,"r",encoding="utf-8") as f:
            summary=json.load(f)
        nodes=[]
        links=[]
        for rec in summary.get("records",[]):
            nid=rec["id"]
            nodes.append({
                "id":nid,
                "label":rec["reason"][:60],
                "severity":rec["severity"]
            })
        for i in range(len(nodes)-1):
            links.append({"source":nodes[i]["id"],"target":nodes[i+1]["id"]})
        return jsonify({"nodes":nodes,"links":links})
    return jsonify({"nodes":[],"links":[]})

def run_dashboard():
    app.run(host="0.0.0.0", port=8090, debug=False)

if __name__=="__main__":
    run_dashboard()

=== FILE: dashboard/app.py (END) ===


=== FILE: current.py ===
"""
Tessrax v12.0 — Unified Runtime Launcher
----------------------------------------
Starts:
  • ContradictionEngine / GovernanceKernel loop
  • FastAPI World Receipt Protocol (port 8080)
  • Flask Dashboard (port 8090)
Everything runs in background threads.
"""

import threading, time, json
from contradiction_engine import ContradictionEngine
from metabolism_adapter import MetabolismAdapter
from governance_kernel import GovernanceKernel
from world_receipt_protocol import app as fastapi_app
from dashboard.app import run_dashboard
import uvicorn

def start_fastapi():
    uvicorn.run(fastapi_app, host="0.0.0.0", port=8080, log_level="warning")

def main_loop():
    ce=ContradictionEngine()
    ma=MetabolismAdapter()
    gk=GovernanceKernel()
    print("🧠 Tessrax runtime active — generating live contradictions every 10 s")
    samples=[
        ("AI improves safety","AI increases risk"),
        ("Data is open","Data is restricted"),
        ("Budget balanced","Budget overspent")
    ]
    while True:
        for a,b in samples:
            c=ce.analyze_pair(a,b)
            metab=ma.ingest(c)
            gk.evaluate_policy({"type":"Semantic","payload":metab})
        ce.export_json("contradictions.json")
        time.sleep(10)

if __name__=="__main__":
    # launch dashboard + API
    threading.Thread(target=run_dashboard, daemon=True).start()
    threading.Thread(target=start_fastapi, daemon=True).start()
    main_loop()

=== FILE: current.py (END) ===


=== FILE: README.md ===
# Tessrax v12.0

### Overview
Tessrax is a self-governing contradiction-metabolism framework that detects, normalizes, evaluates, and visualizes internal conflicts as governance events.

### Features
- **Semantic Contradiction Detection** — transformer embeddings + negation / antonym logic  
- **Metabolic Normalization** — converts contradictions into entropy/stability metrics  
- **Governance Kernel 2.0** — weighted quorum + Merkle-chain ledger integrity  
- **World Receipt Protocol 2.0** — FastAPI ledger endpoint with chain verification  
- **Flask + D3 Dashboard** — real-time contradiction graph on port 8090  
- **Auto-Launch Runtime** — `python current.py` spins up everything  

### Running
```bash
pip install -r requirements.txt
python current.py

Visit:
   •   API:  http://localhost:8080
   •   Dashboard:  http://localhost:8090

Folder Layout

core/      → engines + kernel
dashboard/ → Flask + D3 visualization
demo/      → examples + tests

Notes

All modules auto-install lightweight dependencies (sentence-transformers, nltk, fastapi, flask, uvicorn, d3.js).
Ledger files and contradiction summaries are written to the working directory for transparency.

=== FILE: README.md (END) ===

---

✅ **Full Tessrax v12.0 system complete.**  
Running `python current.py` will now:

1. Auto-start **FastAPI** (8080) + **Flask Dashboard** (8090)  
2. Continuously generate sample contradictions, metabolize them, and log to the ledger  
3. Feed live JSON to D3 for real-time graph visualization  
