{
  "manifest_id": "TESSRAX_METABOLISM_MANIFEST_V1_0",
  "title": "Tessrax Metabolism Framework — Chaos→Order→Persistence→Decay→Renewal",
  "governance": {
    "protocol": "GovernanceKernel v11.1",
    "ledger_path": "data/ledger/metabolism.jsonl",
    "attestation_root": "MERKLE",
    "signature_scheme": "Ed25519",
    "audit_interval": "3600s",
    "defiance_metric": "average_energy / max_energy",
    "repair_metric": "repairs_per_cycle / decay_events"
  },

  "phase_nodes": [
    {
      "id": "tessrax.core.entropy_engine",
      "origin": "Gemini",
      "language": "Python",
      "dependencies": ["pygame"],
      "function": "Particle-based chaos/order/persistence visualization",
      "output_stream": "entropy_field, defiance_score",
      "telemetry": ["average_reaction_time", "scar_decision_latency", "fuel_yield_variance"],
      "governance_hooks": {
        "phase": "order",
        "log_rate": "1s",
        "signature": true
      }
    },
    {
      "id": "tessrax.domains.metabolism.entropic_tides",
      "origin": "DeepSeek",
      "language": "Python",
      "dependencies": ["numpy", "matplotlib", "scipy"],
      "function": "Cellular-automata life loop for entropy metabolism",
      "output_stream": "world_state, defiance_history",
      "governance_hooks": {
        "phase": "persistence",
        "log_rate": "5s",
        "signature": true
      }
    },
    {
      "id": "tessrax.docs.entropy_loop",
      "origin": "Meta",
      "language": "Python",
      "dependencies": ["pygame", "numpy"],
      "function": "Pedagogical reference implementation (educational clarity)",
      "output_stream": "defiance_meter, tending_log",
      "governance_hooks": {
        "phase": "documentation",
        "log_rate": "10s",
        "signature": false
      }
    },
    {
      "id": "tessrax.media.p5_metabolize_tide",
      "origin": "Perplexity",
      "language": "JavaScript (p5.js)",
      "function": "Browser ritual; visual/audio entropy loop",
      "output_stream": "entropy_value, defiance_log",
      "governance_hooks": {
        "phase": "chaos",
        "log_rate": "2s",
        "signature": true
      }
    },
    {
      "id": "tessrax.interface.web.ritual_loop",
      "origin": "Copilot",
      "language": "HTML5 + JS + WebAudio",
      "function": "Interactive front-end with sliders and defiance meter",
      "output_stream": "entropy, repair, half_life, defiance_series",
      "governance_hooks": {
        "phase": "renewal",
        "log_rate": "1s",
        "signature": true
      }
    }
  ],

  "integration_pipeline": {
    "bus": "EventBridge: tessrax.metabolism",
    "schema_version": "1.0",
    "event_types": [
      "ENTROPY_SAMPLE",
      "ORDER_PATTERN",
      "PERSISTENCE_METRIC",
      "REPAIR_EVENT",
      "DEFIANCE_UPDATE"
    ],
    "merge_policy": "last_writer_wins_with_proof",
    "conflict_resolution": "governance_kernel.reconcile()",
    "retention_policy": "retain 90d; fossilize after 10 epochs",
    "checksum": "sha3_512"
  },

  "ledger_fields": {
    "timestamp": "ISO8601",
    "phase": "string",
    "entropy_level": "float",
    "repair_rate": "float",
    "defiance_score": "float",
    "cycle_id": "integer",
    "source_node": "string",
    "signature": "base64",
    "merkle_root": "hex"
  },

  "visualization": {
    "dashboard": "web/entropy_dashboard.html",
    "charts": [
      "Entropy over time",
      "Defiance Meter oscillation",
      "Repair vs. Decay heatmap",
      "Cross-phase coherence matrix"
    ]
  },

  "notes": {
    "philosophy": "Maintenance as meaning; recurrence as sanctity.",
    "cycle_law": "Entropy → Order → Persistence → Decay → Renewal → (repeat)",
    "ethic": "Metabolize the tide, don’t resist it."
  }
}

# tessrax/governance_kernel/metabolism_adapter.py
"""
Metabolism Adapter v1.0
Connects entropy-based modules (Gemini, DeepSeek, Meta, Perplexity, Copilot)
to the GovernanceKernel ledger. Every node sends small JSON packets describing
its local entropy, repair, and defiance states.

The adapter authenticates, normalizes, and appends each to the ledger,
then every hour seals the current slice under a Merkle root signature.
"""

import json
import time
import hashlib
import os
import base64
import ed25519

MANIFEST_PATH = "tessrax/manifest/metabolism_manifest.json"
LEDGER_PATH = "data/ledger/metabolism.jsonl"
MERKLE_SNAPSHOT_PATH = "data/ledger/metabolism_merkle_roots.jsonl"
KEY_PATH = "keys/metabolism_root.key"

# --- Utility: deterministic hashing -------------------------------------------------------

def sha3_512_hex(data: bytes) -> str:
    return hashlib.sha3_512(data).hexdigest()

def merkle_root(hashes):
    """Constructs Merkle root from list of hex digests."""
    if not hashes:
        return None
    level = [bytes.fromhex(h) for h in hashes]
    while len(level) > 1:
        next_level = []
        for i in range(0, len(level), 2):
            left = level[i]
            right = level[i+1] if i+1 < len(level) else left
            next_level.append(hashlib.sha3_512(left + right).digest())
        level = next_level
    return level[0].hex()

# --- Adapter Core ------------------------------------------------------------------------

class MetabolismAdapter:
    def __init__(self):
        with open(MANIFEST_PATH, "r") as f:
            self.manifest = json.load(f)
        self.private_key, self.public_key = self._load_or_create_keys()
        self.buffer = []

    # ------------------------------------------------------------------

    def _load_or_create_keys(self):
        if os.path.exists(KEY_PATH):
            with open(KEY_PATH, "rb") as f:
                sk_bytes = f.read()
            sk = ed25519.SigningKey(sk_bytes)
        else:
            sk = ed25519.SigningKey.generate()
            os.makedirs(os.path.dirname(KEY_PATH), exist_ok=True)
            with open(KEY_PATH, "wb") as f:
                f.write(sk.to_bytes())
        return sk, sk.get_verifying_key()

    # ------------------------------------------------------------------

    def ingest_event(self, packet: dict):
        """
        Receives packets like:
        {
          "timestamp": "2025-10-12T15:00:01Z",
          "phase": "persistence",
          "entropy_level": 0.44,
          "repair_rate": 0.07,
          "defiance_score": 0.61,
          "cycle_id": 203,
          "source_node": "tessrax.domains.metabolism.entropic_tides"
        }
        """
        # Normalize ordering for deterministic hash
        serialized = json.dumps(packet, sort_keys=True).encode()
        packet["checksum"] = sha3_512_hex(serialized)

        # Sign the hash for authenticity
        sig = self.private_key.sign(packet["checksum"].encode())
        packet["signature"] = base64.b64encode(sig).decode()

        # Append to buffer
        self.buffer.append(packet)

    # ------------------------------------------------------------------

    def flush_to_ledger(self):
        """Writes buffered events to ledger file."""
        os.makedirs(os.path.dirname(LEDGER_PATH), exist_ok=True)
        with open(LEDGER_PATH, "a") as f:
            for packet in self.buffer:
                f.write(json.dumps(packet) + "\n")
        self.buffer.clear()

    # ------------------------------------------------------------------

    def seal_snapshot(self):
        """
        Reads the last hour of ledger entries,
        computes a Merkle root, and logs it to a separate file.
        """
        now = time.time()
        cutoff = now - 3600
        recent_entries = []

        if not os.path.exists(LEDGER_PATH):
            return None

        with open(LEDGER_PATH, "r") as f:
            for line in f:
                try:
                    obj = json.loads(line)
                    ts = time.mktime(time.strptime(obj["timestamp"], "%Y-%m-%dT%H:%M:%SZ"))
                    if ts >= cutoff:
                        recent_entries.append(obj)
                except Exception:
                    continue

        hashes = [obj["checksum"] for obj in recent_entries]
        root = merkle_root(hashes)
        if not root:
            return None

        signature = base64.b64encode(self.private_key.sign(root.encode())).decode()
        snapshot = {
            "timestamp": time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime()),
            "entry_count": len(recent_entries),
            "merkle_root": root,
            "signature": signature
        }

        os.makedirs(os.path.dirname(MERKLE_SNAPSHOT_PATH), exist_ok=True)
        with open(MERKLE_SNAPSHOT_PATH, "a") as f:
            f.write(json.dumps(snapshot) + "\n")

        print(f"[MetabolismAdapter] Snapshot sealed: {len(recent_entries)} entries → root {root[:16]}…")
        return snapshot

# --- Ritual Execution Loop ---------------------------------------------------------------

def main():
    adapter = MetabolismAdapter()
    print("Metabolism Adapter active. Listening for events...")

    # In real runtime, these would be messages on the event bus.
    # Here we simulate by reading JSON lines from stdin or generating dummy packets.
    try:
        while True:
            # Simulated event (every 5 seconds)
            fake_event = {
                "timestamp": time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime()),
                "phase": "chaos",
                "entropy_level": round(0.3 + 0.4 * (hash(time.time()) % 100)/100, 3),
                "repair_rate": round(0.05 + 0.05 * (hash(time.time()) % 100)/100, 3),
                "defiance_score": round(0.5 + 0.3 * (hash(time.time()) % 100)/100, 3),
                "cycle_id": int(time.time()) % 100000,
                "source_node": "simulated.node"
            }
            adapter.ingest_event(fake_event)
            adapter.flush_to_ledger()

            # Hourly seal (here simulated every 60s for testing)
            if int(time.time()) % 60 == 0:
                adapter.seal_snapshot()

            time.sleep(5)
    except KeyboardInterrupt:
        print("Adapter halted.")

if __name__ == "__main__":
    main()